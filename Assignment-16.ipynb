{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3bed1ec-ce71-48fd-adf4-0f3b710c8f57",
   "metadata": {},
   "source": [
    "1. In a linear equation, what is the difference between a dependent variable and an independent variable?\n",
    "\n",
    "- **Dependent Variable**: This is the variable that you are trying to predict or explain. It is dependent on the independent variable(s). In a linear equation, it is typically represented as `y`.\n",
    "- **Independent Variable**: These are the variables that you use to predict the dependent variable. They are independent and cause changes in the dependent variable. In a linear equation, they are usually represented as `x`.\n",
    "\n",
    "2. What is the concept of simple linear regression? Give a specific example.\n",
    "\n",
    "- **Simple Linear Regression**: Simple linear regression is a statistical method that models the relationship between two variables by fitting a linear equation to the observed data. The equation takes the form `y = mx + b`, where `y` is the dependent variable, `x` is the independent variable, `m` is the slope, and `b` is the y-intercept.\n",
    "- **Example**: Predicting a person's weight (`y`) based on their height (`x`). The linear equation could be something like `weight = 2.3 * height + 30`, where `2.3` is the slope and `30` is the intercept.\n",
    "\n",
    "3. In a linear regression, define the slope.\n",
    "\n",
    "- **Slope**: The slope in a linear regression represents the rate of change of the dependent variable (`y`) with respect to the independent variable (`x`). It indicates how much `y` changes for a one-unit increase in `x`. Mathematically, the slope is the coefficient `m` in the equation `y = mx + b`.\n",
    "\n",
    "4. Determine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2).\n",
    "\n",
    "- **Slope Calculation**:\n",
    "  - The slope (`m`) is calculated using the formula `m = (y2 - y1) / (x2 - x1)`.\n",
    "  - For points (3, 2) and (2, 2):\n",
    "    - `m = (2 - 2) / (2 - 3) = 0 / -1 = 0`\n",
    "  - **Slope**: The slope of the graph is `0`, indicating a horizontal line.\n",
    "\n",
    "5. In linear regression, what are the conditions for a positive slope?\n",
    "\n",
    "- **Positive Slope Conditions**:\n",
    "  - The slope is positive when an increase in the independent variable (`x`) leads to an increase in the dependent variable (`y`).\n",
    "  - Mathematically, this occurs when `m > 0` in the equation `y = mx + b`.\n",
    "\n",
    "6. In linear regression, what are the conditions for a negative slope?\n",
    "\n",
    "- **Negative Slope Conditions**:\n",
    "  - The slope is negative when an increase in the independent variable (`x`) leads to a decrease in the dependent variable (`y`).\n",
    "  - Mathematically, this occurs when `m < 0` in the equation `y = mx + b`.\n",
    "\n",
    "7. What is multiple linear regression and how does it work?\n",
    "\n",
    "- **Multiple Linear Regression**:\n",
    "  - Multiple linear regression is an extension of simple linear regression where the model predicts the dependent variable (`y`) based on multiple independent variables (`x1`, `x2`, ..., `xn`).\n",
    "  - The equation is of the form `y = b0 + b1*x1 + b2*x2 + ... + bn*xn`, where `b0` is the intercept, and `b1, b2, ..., bn` are the coefficients representing the impact of each independent variable.\n",
    "\n",
    "8. In multiple linear regression, define the number of squares due to error.\n",
    "\n",
    "- **Sum of Squares due to Error (SSE)**:\n",
    "  - SSE measures the total deviation of the observed values from the predicted values. It represents the unexplained variation in the model. Mathematically, it is the sum of the squared differences between the observed and predicted values.\n",
    "\n",
    "9. In multiple linear regression, define the number of squares due to regression.\n",
    "\n",
    "- **Sum of Squares due to Regression (SSR)**:\n",
    "  - SSR measures the explained variation in the model. It represents the sum of the squared differences between the predicted values and the mean of the dependent variable. It indicates how well the independent variables explain the variation in the dependent variable.\n",
    "\n",
    "10. In a regression equation, what is multicollinearity?\n",
    "\n",
    "- **Multicollinearity**:\n",
    "  - Multicollinearity occurs when two or more independent variables in a regression model are highly correlated, meaning they provide redundant information. This can make it difficult to determine the individual effect of each variable on the dependent variable and can lead to unreliable coefficient estimates.\n",
    "\n",
    "11. What is heteroskedasticity, and what does it mean?\n",
    "\n",
    "- **Heteroskedasticity**:\n",
    "  - Heteroskedasticity refers to the condition in which the variance of the errors in a regression model is not constant across all levels of the independent variables. This violates one of the assumptions of linear regression and can lead to inefficient estimates and incorrect conclusions about the relationships in the data.\n",
    "\n",
    "12. Describe the concept of ridge regression.\n",
    "\n",
    "- **Ridge Regression**:\n",
    "  - Ridge regression is a type of linear regression that includes a regularization term to prevent overfitting. It adds a penalty equal to the square of the magnitude of the coefficients to the loss function. This helps to shrink the coefficients and reduces the model's complexity, especially in the presence of multicollinearity.\n",
    "\n",
    "13. Describe the concept of lasso regression.\n",
    "\n",
    "- **Lasso Regression**:\n",
    "  - Lasso regression (Least Absolute Shrinkage and Selection Operator) is a type of linear regression that performs both variable selection and regularization. It adds a penalty equal to the absolute value of the magnitude of the coefficients to the loss function. This can shrink some coefficients to zero, effectively removing some variables from the model.\n",
    "\n",
    "14. What is polynomial regression and how does it work?\n",
    "\n",
    "- **Polynomial Regression**:\n",
    "  - Polynomial regression is a form of regression analysis in which the relationship between the independent variable `x` and the dependent variable `y` is modeled as an nth-degree polynomial. It allows for capturing non-linear relationships between variables by fitting a curve rather than a straight line.\n",
    "\n",
    "15. Describe the basis function.\n",
    "\n",
    "- **Basis Function**:\n",
    "  - A basis function is a function used in regression models to transform the input data. In the context of polynomial regression, basis functions are powers of the original features (e.g., `x`, `x^2`, `x^3`, etc.) that enable the model to fit non-linear relationships.\n",
    "\n",
    "16. Describe how logistic regression works.\n",
    "\n",
    "- **Logistic Regression**:\n",
    "  - Logistic regression is a classification algorithm used to model the probability that a given input belongs to a particular class. It uses the logistic function (or sigmoid function) to map predicted values to probabilities. The output is a probability between 0 and 1, which is then thresholded to make a binary classification decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb610b-26dc-49fd-a68b-b384b1a656c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
